{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNcYjCRCjgWeLZKcUs2h0Gj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eleshuk/machine_learning/blob/main/eleshuk_assignment1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o31OerJlxvu1"
      },
      "outputs": [],
      "source": [
        "# Create a script to train a regression model to predict the response variable \"quality\" given the available explanatory variables for the Wine Quality data set (https://archive.ics.uci.edu/dataset/186/wine+quality) that contains 4898 examples."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score"
      ],
      "metadata": {
        "id": "y2svtjAu1Grt"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount drive to access zip folder in google drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "id": "37hgW0wd1ElS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"/content/drive/My Drive/wine+quality.zip\"\n",
        "with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
        "    file_list = zip_ref.namelist()\n",
        "print(file_list)"
      ],
      "metadata": {
        "id": "nHYn1ld4yMHq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0ed45ea-9bb8-472b-d6fc-15e1fcfb2411"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['winequality-red.csv', 'winequality-white.csv', 'winequality.names']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zip_path = file_path\n",
        "extract_to = \"wine_quality_data\"\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_to)"
      ],
      "metadata": {
        "id": "R0rrd-Hc2S-D"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Look at white wine first, that's the dataset that has 4898 examples (later combine red and white or does it make more sense to keep them separate sine maybe indicators of quality are different?)\n",
        "df = pd.read_csv(\"wine_quality_data/winequality-white.csv\", sep = ';')\n",
        "# df.head()"
      ],
      "metadata": {
        "id": "j5CbnLD52oQE"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read metadata file\n",
        "# with open(\"wine_quality_data/winequality.names\", \"r\") as file:\n",
        "#     print(file.read())"
      ],
      "metadata": {
        "id": "EfpA2AN27E22"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "predict the response variable \"quality\" given the available explanatory variables for the Wine Quality data set"
      ],
      "metadata": {
        "id": "DP7zjlqP_LnA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PyTorch expects numeric data in float32 (for continuous data) - we have a pandas df rn bc of the way that we read in the data\n",
        "\n",
        "# Define features (X) and target (y)\n",
        "features = df.drop(columns=[\"quality\"])  # Drop target variable\n",
        "y_df = df[\"quality\"]  # Target variable\n",
        "\n",
        "# Convert features to a PyTorch tensor\n",
        "X = torch.tensor(features.values, dtype=torch.float32)\n",
        "y = torch.tensor(y_df.astype(np.float32))\n",
        "y = y.view(y.shape[0], 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xw0dbmVKCPjx",
        "outputId": "588c62ca-93fc-4dda-8180-a19c78f54061"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[6.],\n",
              "        [6.],\n",
              "        [6.],\n",
              "        ...,\n",
              "        [6.],\n",
              "        [7.],\n",
              "        [6.]])"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Samples - samples within the dataset\n",
        "# Features - 11\n",
        "\n",
        "# Define number of samples and features\n",
        "n_samples, n_features = X.shape\n",
        "# input size - number of features (11)\n",
        "# output size - quality (1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q5Ky0VT9Ir-o",
        "outputId": "d579c18e-bd41-4e8c-8044-3c9986c58d2e"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4898 11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Linear model f = wx + b\n",
        "input_size = n_features\n",
        "output_size = 1 # (quality)\n",
        "model = nn.Linear(input_size, output_size)\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0lgerYatI5sw",
        "outputId": "2bf57006-4ded-4da2-c1c0-eef2653f0f2d"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=11, out_features=1, bias=True)"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss and optimizer\n",
        "learning_rate = 0.01\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "fkrupSF2J2Ho"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# y_predicted = model(X)"
      ],
      "metadata": {
        "id": "bvuNvUq7LO1c",
        "outputId": "b43758b5-be33-47b0-fa35-1464144586e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[21.9072],\n",
              "        [23.9398],\n",
              "        [11.1015],\n",
              "        ...,\n",
              "        [14.7738],\n",
              "        [17.7923],\n",
              "        [14.5116]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3) Training loop\n",
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "    # Forward pass and loss\n",
        "    y_predicted = model(X)\n",
        "    print(y_predicted)\n",
        "    loss = criterion(y_predicted, y)\n",
        "\n",
        "    # Backward pass and update\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # zero grad before new step\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    if (epoch+1) % 10 == 0:\n",
        "        print(f'epoch: {epoch+1}, loss = {loss.item():.4f}')"
      ],
      "metadata": {
        "id": "rLirlV-0J4Ac",
        "outputId": "1d8dd643-0348-418a-9a94-0139954d3b41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[nan],\n",
            "        [nan],\n",
            "        [nan],\n",
            "        ...,\n",
            "        [nan],\n",
            "        [nan],\n",
            "        [nan]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[nan],\n",
            "        [nan],\n",
            "        [nan],\n",
            "        ...,\n",
            "        [nan],\n",
            "        [nan],\n",
            "        [nan]], grad_fn=<AddmmBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([4898])) that is different to the input size (torch.Size([4898, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[nan],\n",
            "        [nan],\n",
            "        [nan],\n",
            "        ...,\n",
            "        [nan],\n",
            "        [nan],\n",
            "        [nan]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[nan],\n",
            "        [nan],\n",
            "        [nan],\n",
            "        ...,\n",
            "        [nan],\n",
            "        [nan],\n",
            "        [nan]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[nan],\n",
            "        [nan],\n",
            "        [nan],\n",
            "        ...,\n",
            "        [nan],\n",
            "        [nan],\n",
            "        [nan]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[nan],\n",
            "        [nan],\n",
            "        [nan],\n",
            "        ...,\n",
            "        [nan],\n",
            "        [nan],\n",
            "        [nan]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[nan],\n",
            "        [nan],\n",
            "        [nan],\n",
            "        ...,\n",
            "        [nan],\n",
            "        [nan],\n",
            "        [nan]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[nan],\n",
            "        [nan],\n",
            "        [nan],\n",
            "        ...,\n",
            "        [nan],\n",
            "        [nan],\n",
            "        [nan]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[nan],\n",
            "        [nan],\n",
            "        [nan],\n",
            "        ...,\n",
            "        [nan],\n",
            "        [nan],\n",
            "        [nan]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[nan],\n",
            "        [nan],\n",
            "        [nan],\n",
            "        ...,\n",
            "        [nan],\n",
            "        [nan],\n",
            "        [nan]], grad_fn=<AddmmBackward0>)\n",
            "epoch: 10, loss = nan\n",
            "tensor([[nan],\n",
            "        [nan],\n",
            "        [nan],\n",
            "        ...,\n",
            "        [nan],\n",
            "        [nan],\n",
            "        [nan]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[nan],\n",
            "        [nan],\n",
            "        [nan],\n",
            "        ...,\n",
            "        [nan],\n",
            "        [nan],\n",
            "        [nan]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[nan],\n",
            "        [nan],\n",
            "        [nan],\n",
            "        ...,\n",
            "        [nan],\n",
            "        [nan],\n",
            "        [nan]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[nan],\n",
            "        [nan],\n",
            "        [nan],\n",
            "        ...,\n",
            "        [nan],\n",
            "        [nan],\n",
            "        [nan]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[nan],\n",
            "        [nan],\n",
            "        [nan],\n",
            "        ...,\n",
            "        [nan],\n",
            "        [nan],\n",
            "        [nan]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[nan],\n",
            "        [nan],\n",
            "        [nan],\n",
            "        ...,\n",
            "        [nan],\n",
            "        [nan],\n",
            "        [nan]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[nan],\n",
            "        [nan],\n",
            "        [nan],\n",
            "        ...,\n",
            "        [nan],\n",
            "        [nan],\n",
            "        [nan]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[nan],\n",
            "        [nan],\n",
            "        [nan],\n",
            "        ...,\n",
            "        [nan],\n",
            "        [nan],\n",
            "        [nan]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[nan],\n",
            "        [nan],\n",
            "        [nan],\n",
            "        ...,\n",
            "        [nan],\n",
            "        [nan],\n",
            "        [nan]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[nan],\n",
            "        [nan],\n",
            "        [nan],\n",
            "        ...,\n",
            "        [nan],\n",
            "        [nan],\n",
            "        [nan]], grad_fn=<AddmmBackward0>)\n",
            "epoch: 20, loss = nan\n",
            "tensor([[nan],\n",
            "        [nan],\n",
            "        [nan],\n",
            "        ...,\n",
            "        [nan],\n",
            "        [nan],\n",
            "        [nan]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[nan],\n",
            "        [nan],\n",
            "        [nan],\n",
            "        ...,\n",
            "        [nan],\n",
            "        [nan],\n",
            "        [nan]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[nan],\n",
            "        [nan],\n",
            "        [nan],\n",
            "        ...,\n",
            "        [nan],\n",
            "        [nan],\n",
            "        [nan]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[nan],\n",
            "        [nan],\n",
            "        [nan],\n",
            "        ...,\n",
            "        [nan],\n",
            "        [nan],\n",
            "        [nan]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[nan],\n",
            "        [nan],\n",
            "        [nan],\n",
            "        ...,\n",
            "        [nan],\n",
            "        [nan],\n",
            "        [nan]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[nan],\n",
            "        [nan],\n",
            "        [nan],\n",
            "        ...,\n",
            "        [nan],\n",
            "        [nan],\n",
            "        [nan]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[nan],\n",
            "        [nan],\n",
            "        [nan],\n",
            "        ...,\n",
            "        [nan],\n",
            "        [nan],\n",
            "        [nan]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[nan],\n",
            "        [nan],\n",
            "        [nan],\n",
            "        ...,\n",
            "        [nan],\n",
            "        [nan],\n",
            "        [nan]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[nan],\n",
            "        [nan],\n",
            "        [nan],\n",
            "        ...,\n",
            "        [nan],\n",
            "        [nan],\n",
            "        [nan]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[nan],\n",
            "        [nan],\n",
            "        [nan],\n",
            "        ...,\n",
            "        [nan],\n",
            "        [nan],\n",
            "        [nan]], grad_fn=<AddmmBackward0>)\n",
            "epoch: 30, loss = nan\n",
            "tensor([[nan],\n",
            "        [nan],\n",
            "        [nan],\n",
            "        ...,\n",
            "        [nan],\n",
            "        [nan],\n",
            "        [nan]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[nan],\n",
            "        [nan],\n",
            "        [nan],\n",
            "        ...,\n",
            "        [nan],\n",
            "        [nan],\n",
            "        [nan]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[nan],\n",
            "        [nan],\n",
            "        [nan],\n",
            "        ...,\n",
            "        [nan],\n",
            "        [nan],\n",
            "        [nan]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[nan],\n",
            "        [nan],\n",
            "        [nan],\n",
            "        ...,\n",
            "        [nan],\n",
            "        [nan],\n",
            "        [nan]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[nan],\n",
            "        [nan],\n",
            "        [nan],\n",
            "        ...,\n",
            "        [nan],\n",
            "        [nan],\n",
            "        [nan]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[nan],\n",
            "        [nan],\n",
            "        [nan],\n",
            "        ...,\n",
            "        [nan],\n",
            "        [nan],\n",
            "        [nan]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[nan],\n",
            "        [nan],\n",
            "        [nan],\n",
            "        ...,\n",
            "        [nan],\n",
            "        [nan],\n",
            "        [nan]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[nan],\n",
            "        [nan],\n",
            "        [nan],\n",
            "        ...,\n",
            "        [nan],\n",
            "        [nan],\n",
            "        [nan]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[nan],\n",
            "        [nan],\n",
            "        [nan],\n",
            "        ...,\n",
            "        [nan],\n",
            "        [nan],\n",
            "        [nan]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[nan],\n",
            "        [nan],\n",
            "        [nan],\n",
            "        ...,\n",
            "        [nan],\n",
            "        [nan],\n",
            "        [nan]], grad_fn=<AddmmBackward0>)\n",
            "epoch: 40, loss = nan\n",
            "tensor([[nan],\n",
            "        [nan],\n",
            "        [nan],\n",
            "        ...,\n",
            "        [nan],\n",
            "        [nan],\n",
            "        [nan]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[nan],\n",
            "        [nan],\n",
            "        [nan],\n",
            "        ...,\n",
            "        [nan],\n",
            "        [nan],\n",
            "        [nan]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[nan],\n",
            "        [nan],\n",
            "        [nan],\n",
            "        ...,\n",
            "        [nan],\n",
            "        [nan],\n",
            "        [nan]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[nan],\n",
            "        [nan],\n",
            "        [nan],\n",
            "        ...,\n",
            "        [nan],\n",
            "        [nan],\n",
            "        [nan]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[nan],\n",
            "        [nan],\n",
            "        [nan],\n",
            "        ...,\n",
            "        [nan],\n",
            "        [nan],\n",
            "        [nan]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[nan],\n",
            "        [nan],\n",
            "        [nan],\n",
            "        ...,\n",
            "        [nan],\n",
            "        [nan],\n",
            "        [nan]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[nan],\n",
            "        [nan],\n",
            "        [nan],\n",
            "        ...,\n",
            "        [nan],\n",
            "        [nan],\n",
            "        [nan]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[nan],\n",
            "        [nan],\n",
            "        [nan],\n",
            "        ...,\n",
            "        [nan],\n",
            "        [nan],\n",
            "        [nan]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[nan],\n",
            "        [nan],\n",
            "        [nan],\n",
            "        ...,\n",
            "        [nan],\n",
            "        [nan],\n",
            "        [nan]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[nan],\n",
            "        [nan],\n",
            "        [nan],\n",
            "        ...,\n",
            "        [nan],\n",
            "        [nan],\n",
            "        [nan]], grad_fn=<AddmmBackward0>)\n",
            "epoch: 50, loss = nan\n",
            "tensor([[nan],\n",
            "        [nan],\n",
            "        [nan],\n",
            "        ...,\n",
            "        [nan],\n",
            "        [nan],\n",
            "        [nan]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[nan],\n",
            "        [nan],\n",
            "        [nan],\n",
            "        ...,\n",
            "        [nan],\n",
            "        [nan],\n",
            "        [nan]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[nan],\n",
            "        [nan],\n",
            "        [nan],\n",
            "        ...,\n",
            "        [nan],\n",
            "        [nan],\n",
            "        [nan]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[nan],\n",
            "        [nan],\n",
            "        [nan],\n",
            "        ...,\n",
            "        [nan],\n",
            "        [nan],\n",
            "        [nan]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[nan],\n",
            "        [nan],\n",
            "        [nan],\n",
            "        ...,\n",
            "        [nan],\n",
            "        [nan],\n",
            "        [nan]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[nan],\n",
            "        [nan],\n",
            "        [nan],\n",
            "        ...,\n",
            "        [nan],\n",
            "        [nan],\n",
            "        [nan]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[nan],\n",
            "        [nan],\n",
            "        [nan],\n",
            "        ...,\n",
            "        [nan],\n",
            "        [nan],\n",
            "        [nan]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[nan],\n",
            "        [nan],\n",
            "        [nan],\n",
            "        ...,\n",
            "        [nan],\n",
            "        [nan],\n",
            "        [nan]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[nan],\n",
            "        [nan],\n",
            "        [nan],\n",
            "        ...,\n",
            "        [nan],\n",
            "        [nan],\n",
            "        [nan]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[nan],\n",
            "        [nan],\n",
            "        [nan],\n",
            "        ...,\n",
            "        [nan],\n",
            "        [nan],\n",
            "        [nan]], grad_fn=<AddmmBackward0>)\n",
            "epoch: 60, loss = nan\n",
            "tensor([[nan],\n",
            "        [nan],\n",
            "        [nan],\n",
            "        ...,\n",
            "        [nan],\n",
            "        [nan],\n",
            "        [nan]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[nan],\n",
            "        [nan],\n",
            "        [nan],\n",
            "        ...,\n",
            "        [nan],\n",
            "        [nan],\n",
            "        [nan]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[nan],\n",
            "        [nan],\n",
            "        [nan],\n",
            "        ...,\n",
            "        [nan],\n",
            "        [nan],\n",
            "        [nan]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[nan],\n",
            "        [nan],\n",
            "        [nan],\n",
            "        ...,\n",
            "        [nan],\n",
            "        [nan],\n",
            "        [nan]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[nan],\n",
            "        [nan],\n",
            "        [nan],\n",
            "        ...,\n",
            "        [nan],\n",
            "        [nan],\n",
            "        [nan]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[nan],\n",
            "        [nan],\n",
            "        [nan],\n",
            "        ...,\n",
            "        [nan],\n",
            "        [nan],\n",
            "        [nan]], grad_fn=<AddmmBackward0>)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-81-a73a4c4718f5>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# Backward pass and update\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    624\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m             )\n\u001b[0;32m--> 626\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    627\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    824\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Start by standardizing the data - benefits = not all numeric explanatory variables are of the same scale, so standardizing prevents the model from giving importance to a variable of a larger scale\n",
        "\n"
      ],
      "metadata": {
        "id": "k9osoUri_NQ-"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)"
      ],
      "metadata": {
        "id": "LoQqdmtx_tM4"
      },
      "execution_count": 31,
      "outputs": []
    }
  ]
}